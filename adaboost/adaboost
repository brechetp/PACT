Pre-requis:
-Matrice d'apprentissage M de n exemple chaqun decrit par l attribut
-Vecteur de classe Y
-Nombre d'iteration T
-Fonction donnant le classificateur a souche de decision le plus efficace : FonctionClassificateur

Sorties:
-Vecteur de coefficient A
-Vecteur de classificateur souche H

Tableau D de taille n
Tableau H de taille T
Tableau A de taille T

Pour i de 1 a n, Faire
	D[i]=1/n 		 	//On initialise la distribution avec des poids identiques
FinFaire


Pour t de 1 a T, Faire
	-H[t] <- FonctionClassifieur(D,X,Y)
	-A[t] <- 1/2*ln((1-e[t])/e[t])   	//e[t] represente l'erreur que fait le 	classificateur sur la base
	
	-Pour i de 1 a m Faire 			//Debut du calcul des nouveaus coefficients
		 -D[i]<-D[i]exp(A[t]) si H[t]( M[i] ) <> Y[i]
		 -D[i]<-D[i]exp(-A[t]) sinon
	FinFaire
	
	Denom = somme (D[i],i=1..m) 		//On calcule la somme totale des D[i] pour ensuite les normaliser
	-Pour i de 1 a m Faire
		D[i]<-D[i]/Denom
	FinFaire
	
FinFaire

Renvoyer A et H